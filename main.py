# ç®€å•ç›´æ¥çš„èŠ‚ç‚¹æ”¶é›†ç¨‹åº
import requests
import re

print("ğŸš€ å¯åŠ¨èŠ‚ç‚¹æ”¶é›†ç¨‹åº...")

# ä½¿ç”¨å¯é çš„è®¢é˜…æº
sources = [
    "https://raw.githubusercontent.com/Epodonios/v2ray-configs/main/All_Configs_base64_Sub.txt",
    "https://raw.githubusercontent.com/moez06/V2ray-configs/main/All_Configs_base64_Sub.txt",
    "https://sub.sharecentre.online/sub",  # è¿™ä¸ªæºé€šå¸¸æœ‰å¾ˆå¤šèŠ‚ç‚¹
]

all_links = []

for url in sources:
    print(f"\nğŸ“¥ å°è¯•: {url}")
    try:
        response = requests.get(url, timeout=20)
        print(f"  çŠ¶æ€ç : {response.status_code}")
        print(f"  å†…å®¹é•¿åº¦: {len(response.text)} å­—ç¬¦")
        
        if response.status_code == 200:
            content = response.text
            
            # æ–¹æ³•1ï¼šç›´æ¥æœç´¢ "vmess://"
            if "vmess://" in content:
                # æå–æ‰€æœ‰vmessé“¾æ¥
                lines = content.split('\n')
                for line in lines:
                    if "vmess://" in line:
                        # æ¸…ç†é“¾æ¥
                        link = line.strip()
                        # å»é™¤å‰åçš„å¼•å·æˆ–ç©ºæ ¼
                        link = link.replace('"', '').replace("'", "").strip()
                        if link.startswith("vmess://"):
                            all_links.append(link)
                            print(f"  æ‰¾åˆ°: {link[:60]}...")
            
            # æ–¹æ³•2ï¼šæ­£åˆ™æŸ¥æ‰¾
            patterns = [
                r'vmess://[A-Za-z0-9+/=\-_]+',
                r'vless://[A-Za-z0-9%\-_\.:@]+',
                r'trojan://[A-Za-z0-9%\-_\.:@]+'
            ]
            
            for pattern in patterns:
                matches = re.findall(pattern, content)
                if matches:
                    for match in matches:
                        if match not in all_links:
                            all_links.append(match)
                    print(f"  æ­£åˆ™æ‰¾åˆ° {len(matches)} ä¸ª {pattern.split(':')[0]} é“¾æ¥")
    
    except Exception as e:
        print(f"  âŒ é”™è¯¯: {str(e)[:50]}")

print(f"\nğŸ“Š ç»“æœç»Ÿè®¡:")
print(f"æ€»å…±æ‰¾åˆ°: {len(all_links)} ä¸ªé“¾æ¥")

if all_links:
    # å»é‡
    unique_links = []
    seen = set()
    for link in all_links:
        if link not in seen:
            seen.add(link)
            unique_links.append(link)
    
    print(f"å»é‡å: {len(unique_links)} ä¸ªå”¯ä¸€é“¾æ¥")
    
    # ä¿å­˜åˆ°æ–‡ä»¶
    with open('nodes.txt', 'w', encoding='utf-8') as f:
        for link in unique_links:
            f.write(link + '\n')
    
    print("âœ… æˆåŠŸä¿å­˜åˆ° nodes.txt")
    
    # æ˜¾ç¤ºä¸€äº›ç¤ºä¾‹
    print("\nğŸ“‹ é“¾æ¥ç¤ºä¾‹:")
    for i, link in enumerate(unique_links[:3]):
        print(f"{i+1}. {link[:80]}...")
    
else:
    print("âš ï¸  æ²¡æœ‰æ‰¾åˆ°æ ‡å‡†æ ¼å¼çš„é“¾æ¥")
    print("æ­£åœ¨ä»å…¶ä»–æºè·å–...")
    
    # å¤‡ç”¨æ–¹æ¡ˆï¼šä»å·²çŸ¥çš„å¥½ç”¨æºè·å–
    try:
        backup_url = "https://raw.githubusercontent.com/mianfeifq/share/main/README.md"
        print(f"å°è¯•å¤‡ç”¨æº: {backup_url}")
        resp = requests.get(backup_url, timeout=15)
        
        if resp.status_code == 200:
            # è¿™ä¸ªæºé€šå¸¸æœ‰å¾ˆå¤šé“¾æ¥
            backup_content = resp.text
            backup_links = re.findall(r'vmess://[A-Za-z0-9+/=]+', backup_content)
            
            if backup_links:
                print(f"ä»å¤‡ç”¨æºæ‰¾åˆ° {len(backup_links)} ä¸ªé“¾æ¥")
                with open('nodes.txt', 'w', encoding='utf-8') as f:
                    for link in backup_links[:20]:  # åªå–å‰20ä¸ª
                        f.write(link + '\n')
                print("âœ… ä»å¤‡ç”¨æºä¿å­˜äº†é“¾æ¥")
            else:
                # æœ€åæ–¹æ¡ˆï¼šåˆ›å»ºæµ‹è¯•æ–‡ä»¶
                create_test_file()
        else:
            create_test_file()
            
    except:
        create_test_file()

def create_test_file():
    """åˆ›å»ºæµ‹è¯•æ–‡ä»¶"""
    print("åˆ›å»ºæµ‹è¯•èŠ‚ç‚¹æ–‡ä»¶...")
    test_links = [
        "vmess://eyJhZGQiOiJ2bS5leGFtcGxlLmNvbSIsInBvcnQiOiI0NDMiLCJpZCI6IjEyMzQ1Njc4OTAtMTIzNC01Njc4LTkwMTItMzQ1Njc4OTAxMiIsImFpZCI6IjAiLCJuZXQiOiJ3cyIsInR5cGUiOiJub25lIiwiaG9zdCI6IiIsInBhdGgiOiIiLCJ0bHMiOiJ0bHMifQ==",
        "vmess://eyJhZGQiOiJub2RlMS5mcmVlcHJveHkub3JnIiwicG9ydCI6IjgwODAiLCJpZCI6ImFiY2RlZmdoaWprbG1ub3BxcnN0dXZ3IiwgImFpZCI6IjAiLCJuZXQiOiJ0Y3AiLCJ0eXBlIjoibm9uZSIsInBzIjoiVGVzdCBOb2RlIDEifQ==",
        "vmess://eyJhZGQiOiJmcmVlLnZwbi5jb20iLCJwb3J0IjoiNDQzIiwiaWQiOiI1Njc4OTAxMi0zNDU2LTc4OTAtMTIzNDU2Nzg5MDEyIiwiYWlkIjoiMCIsIm5ldCI6IndzIiwidHlwZSI6Im5vbmUiLCJob3N0IjoiIiwicGF0aCI6IiIsInRscyI6InRscyJ9"
    ]
    
    with open('nodes.txt', 'w', encoding='utf-8') as f:
        for link in test_links:
            f.write(link + '\n')
    
    print("âœ… å·²åˆ›å»ºæµ‹è¯• nodes.txt æ–‡ä»¶")

print("\nâœ¨ ç¨‹åºæ‰§è¡Œå®Œæˆï¼")
